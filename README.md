# SSMphony

## ğŸ“Œ 1. Overview

**SSMphony** is a Hindi-language text-to-speech (TTS) model built using a Structured State Space (S4) core for sequence modeling. It maps text input to speech waveforms via learned latent representations.

Key features:

- High-quality TTS in Hindi
- Efficient long-range dependency modeling using S4 layers
- Scalable training and inference

The architecture consists of:

```
Text â†’ Tokenizer â†’ Embeddings â†’ S4 Encoder/Decoder â†’ Projection â†’ Vocoder
```

The core innovation is the **S4 (Structured State Space)** layer which replaces traditional RNN/Transformer blocks for long sequence modeling.

---

## ğŸ“Œ 2. What Is Structured State Space (S4)?

S4 is a state-space model adapted for deep learning that can process very long sequences with linear-time complexity while retaining long-range signal information. It is inspired by continuous-time state-space models used in control theory.

### ğŸ”¹ Continuous-Time State Space (CTSSM)

At the continuous level:

$$
\dot{x}(t) = A x(t) + B u(t)
$$

$$
y(t) = C x(t) + D u(t)
$$

Where:

- $u(t)$ is the input signal
- $x(t)$ is the latent state
- $y(t)$ is the output
- $A, B, C, D$ are learned matrices

This describes how the hidden state evolves given the input over time.

### ğŸ”¹ Discrete Sequence Form

Discretizing with step $k$:

$$
x_k = \bar{A} x_{k-1} + \bar{B} u_k
$$

$$
 y_k = \bar{C} x_k + \bar{D} u_k
$$

Here:

- $(\bar{A}, \bar{B}, \bar{C}, \bar{D})$ are discrete state matrices
- Each new output depends on the current input and state

### ğŸ”¹ Efficient Computation with HiPPO & Diagonalization

S4 uses HiPPO matrices and diagonalization to stabilize learning and cover long contexts. Standard RNNs can suffer from vanishing/exploding gradients â€” S4 mitigates this by using structured state-space parameterizations.

A key computational trick is:

$$
\bar{A} = V \Lambda V^{-1}
$$

Where $\Lambda$ is diagonal â€” this reduces complexity and enables fast sequence convolution via FFT.

### ğŸ”¹ Convolutional View

S4 can be shown to implement a long convolution:

$$
y = k * u
$$

Where the convolution kernel $k$ arises from state propagation. This means S4 acts like a learned convolution filter with a super-long receptive field.

---

## ğŸ“Œ 3. SSMphony Architecture

Below is a typical sequence pipeline included in this repo based on common TTS structure and S4 modules:

```
input_text
   â†“ tokenizer
phoneme_ids / tokens
   â†“ embeddings (E)
embedded sequence
   â†“ S4 layers
latent features
   â†“ linear layers (projection)
mel-spectrogram
   â†“ vocoder
waveform
```

### ğŸ™ï¸ 3.1 Text â†’ Tokens

Given a text string such as:

```
"à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¦à¥à¤¨à¤¿à¤¯à¤¾"
```

We map to a sequence of token IDs:

$$
T = [t_1, t_2, \ldots, t_N]
$$

These feed into an embedding layer:

$$
E = W_e T
$$

Where $W_e \in \mathbb{R}^{d\times V}$ and $V$ is the token vocabulary size.

### ğŸ™ï¸ 3.2 S4 Encoder/Decoder

Tokens â†’ hidden:

$$
H^{(0)} = E
$$

Then for every layer $\ell$:

$$
H^{(\ell)} = \mathrm{S4Layer}(H^{(\ell-1)})
$$

Each S4Layer implements a convolutional-like update:

$$
H^{(\ell)} = \mathrm{Convolution}(H^{(\ell-1)}, k)
$$

Where kernel $k$ is derived from state-space propagation matrices with exponential stability.

### ğŸ™ï¸ 3.3 Linear Projection â†’ Mel Spectrogram

For time indices:

$$
M = W_o H^{(L)} + b
$$

Where:

- $M \in \mathbb{R}^{T\times F}$ is the mel spectrogram
- $W_o, b$ are trained output projection parameters

Mel spectrogram represents frequency components over time.

### ğŸ™ï¸ 3.4 Vocoder

The mel spectrogram is then converted to waveform using a neural vocoder (e.g., HiFi-GAN, WaveRNN). If yours is custom, it reconstructs audio samples.

---

## ğŸ“Œ 4. Training Objective

The model minimizes spectrogram reconstruction loss.

### ğŸŸ¨ MSE Loss

$$
\mathcal{L}_{\mathrm{MSE}} = \frac{1}{TF} \sum_{t=1}^T \sum_{f=1}^F (M_{t,f} - \hat{M}_{t,f})^2
$$


## ğŸ“Œ 5. Model Architecture (Diagram View)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Text          â”‚
â”‚  (Hindi Sentence)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Tokenizer /      â”‚
â”‚   Phoneme Encoder    â”‚
â”‚  (Text â†’ Tokens)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Embedding Layer   â”‚
â”‚  Tokens â†’ Vectors    â”‚
â”‚  (N Ã— d_model)       â”‚
â””â”€â”€â”€â”€â”€â”€ï¿½ï¿½â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      S4 ENCODER      â•‘
â•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  [ S4 Block Ã— L ]    â•‘
â•‘  â€¢ Long-range text   â•‘
â•‘    dependency model  â•‘
â•‘  â€¢ Residual + Norm   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Latent Representationâ”‚
â”‚   (Linguistic Info)  â”‚
â”‚     N Ã— d_model      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      S4 DECODER      â•‘
â•‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â•‘
â•‘  [ S4 Block Ã— L ]    â•‘
â•‘  â€¢ Duration modeling â•‘
â•‘  â€¢ Prosody & rhythm  â•‘
â•‘  â€¢ Temporal expand   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Linear Projection  â”‚
â”‚  d_model â†’ Mel bins  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Mel-Spectrogram    â”‚
â”‚    (T Ã— F bins)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Vocoder        â”‚
â”‚ (HiFi-GAN / WaveRNN) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Audio Waveform     â”‚
â”‚   (Speech Output)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ”¹ Architectural Highlights

- Encoder: Learns long-range linguistic structure from text using stacked S4 blocks.
- Decoder: Expands text representations into time-aligned acoustic features (duration, prosody).
- S4 Blocks: Replace attention and recurrence with structured state-space sequence modeling.
- Parallel & Efficient: No autoregressive bottlenecks; scalable to long utterances.

---

## ğŸ“Œ 6. File Annotations

| Filename        | Purpose                                                                       |
| --------------- | ----------------------------------------------------------------------------- |
| `dataset.py`    | Loads text and speech data; text tokenization and mel extraction              |
| `s4.py`         | Core S4 layer implementation â€” includes state matrices, convolution utilities |
| `tts_model.py`  | Builds TTS model: embedding â†’ S4 blocks â†’ projection                          |
| `train.py`      | Training loop: loss, optimizer, batching                                      |
| `test_s4.py`    | Tests for the S4 layers                                                       |
| `test_model.py` | Unit tests for model sanity                                                   |

---

## ğŸ“Œ 7. Key Hyperparameters

| Parameter    | Meaning                      |
| ------------ | ---------------------------- |
| `d_model`    | Hidden dim (S4 feature size) |
| `L`          | Number of S4 blocks          |
| `lr`         | Learning rate                |
| `batch_size` | Samples per mini-batch       |
| `warmup`     | Warmup steps for optimizer   |
| `max_seq`    | Max text length              |
